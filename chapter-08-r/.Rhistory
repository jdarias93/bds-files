rownames(mat) <- c()
mat[-c(1)]
}
cr <- corr("specdata",150)
corr("specdata",400)
head(cr)
summary(cr)
cr <- corr("specdata",400)
head(cr)
summary(cr)
cr <- corr("specdata",5000)
summary(cr)
length(cr)
cr == 0
cr == logical(0)
cr == TRUE
cr
cr == FALSE
corr <- function(directory, threshold = 0) {
setwd("~/Desktop/grunt-work/Coursera/DataScienceJohnHopkins/02-R_Programming/")
nobs <- 0
id <- 1:332
mat <- matrix(ncol=1,nrow=1)
for (i in id) {
nobs <- 0
if(i < 10) {
j <- paste0("00",i)
} else if(10 <= i & i < 100) {
j <- paste0("0",i)
} else {
j <- as.character(i)
}
ndir <- paste0(directory,"/",j,".csv")
data <- read.csv(ndir)
attach(data)
s <- sulfate
n <- nitrate
detach(data)
for (j in 1:length(s)) {
if(is.na(s[j]) == FALSE && is.na(n[j]) == FALSE) {
nobs <- nobs + 1
} else {
next
}
}
if(nobs > threshold) {
corre <- cor(s,n,use="complete.obs")
mat <- rbind(mat,corre)
} else {
next
}
}
rownames(mat) <- c()
print(mat)
mat[-c(1)]
}
corr("specdata",5000)
is.na(corr("specdata",5000))
cr <- corr("specdata")
summary(cr)
is.na(corr("specdata",5000))
corr("specdata",5000)
corr <- function(directory, threshold = 0) {
setwd("~/Desktop/grunt-work/Coursera/DataScienceJohnHopkins/02-R_Programming/")
nobs <- 0
id <- 1:332
mat <- matrix(ncol=1,nrow=1)
for (i in id) {
nobs <- 0
if(i < 10) {
j <- paste0("00",i)
} else if(10 <= i & i < 100) {
j <- paste0("0",i)
} else {
j <- as.character(i)
}
ndir <- paste0(directory,"/",j,".csv")
data <- read.csv(ndir)
attach(data)
s <- sulfate
n <- nitrate
detach(data)
for (j in 1:length(s)) {
if(is.na(s[j]) == FALSE && is.na(n[j]) == FALSE) {
nobs <- nobs + 1
} else {
next
}
}
if(nobs > threshold) {
corre <- cor(s,n,use="complete.obs")
mat <- rbind(mat,corre)
} else {
next
}
}
rownames(mat) <- c()
mat[-c(1)]
mat <- as.vector(mat)
}
corr("specdata",5000)
cr
cr <- corr("specdata",5000)
cr
is.na(cr)
corr <- function(directory, threshold = 0) {
setwd("~/Desktop/grunt-work/Coursera/DataScienceJohnHopkins/02-R_Programming/")
nobs <- 0
id <- 1:332
mat <- matrix(ncol=1,nrow=1)
for (i in id) {
nobs <- 0
if(i < 10) {
j <- paste0("00",i)
} else if(10 <= i & i < 100) {
j <- paste0("0",i)
} else {
j <- as.character(i)
}
ndir <- paste0(directory,"/",j,".csv")
data <- read.csv(ndir)
attach(data)
s <- sulfate
n <- nitrate
detach(data)
for (j in 1:length(s)) {
if(is.na(s[j]) == FALSE && is.na(n[j]) == FALSE) {
nobs <- nobs + 1
} else {
next
}
}
if(nobs > threshold) {
corre <- cor(s,n,use="complete.obs")
mat <- rbind(mat,corre)
} else {
next
}
}
rownames(mat) <- c()
mat[-c(1)]
mat <- as.vector(mat)
if(is.na(mat) == TRUE) {
mat <- 0
as.vector(mat)
} else {
next
}
}
cr <- corr("specdata",5000)
cr
summary(cr)
cr <- corr("specdata",150)
cr
corr <- function(directory, threshold = 0) {
setwd("~/Desktop/grunt-work/Coursera/DataScienceJohnHopkins/02-R_Programming/")
nobs <- 0
id <- 1:332
mat <- matrix(ncol=1,nrow=1)
for (i in id) {
nobs <- 0
if(i < 10) {
j <- paste0("00",i)
} else if(10 <= i & i < 100) {
j <- paste0("0",i)
} else {
j <- as.character(i)
}
ndir <- paste0(directory,"/",j,".csv")
data <- read.csv(ndir)
attach(data)
s <- sulfate
n <- nitrate
detach(data)
for (j in 1:length(s)) {
if(is.na(s[j]) == FALSE && is.na(n[j]) == FALSE) {
nobs <- nobs + 1
} else {
next
}
}
if(nobs > threshold) {
corre <- cor(s,n,use="complete.obs")
mat <- rbind(mat,corre)
} else {
next
}
}
rownames(mat) <- c()
mat <- mat[-c(1)]
mat <- as.vector(mat)
if(is.na(mat) == TRUE) {
mat <- 0
as.vector(mat)
} else {
next
}
}
cr <- corr("specdata",150)
xr
cr
corr <- function(directory, threshold = 0) {
setwd("~/Desktop/grunt-work/Coursera/DataScienceJohnHopkins/02-R_Programming/")
nobs <- 0
id <- 1:332
mat <- matrix(ncol=1,nrow=1)
for (i in id) {
nobs <- 0
if(i < 10) {
j <- paste0("00",i)
} else if(10 <= i & i < 100) {
j <- paste0("0",i)
} else {
j <- as.character(i)
}
ndir <- paste0(directory,"/",j,".csv")
data <- read.csv(ndir)
attach(data)
s <- sulfate
n <- nitrate
detach(data)
for (j in 1:length(s)) {
if(is.na(s[j]) == FALSE && is.na(n[j]) == FALSE) {
nobs <- nobs + 1
} else {
next
}
}
if(nobs > threshold) {
corre <- cor(s,n,use="complete.obs")
mat <- rbind(mat,corre)
} else {
next
}
}
rownames(mat) <- c()
mat[-c(1)]
}
xr
cr <- corr("specdata",150)
cr
d$depth
head(d, n=3)
nrow(d)
ncol(d) # Check # columns
dim(d) # Check dimensions
colnames(d)
colnames(d)[12] <- "Percent.GC"
x <- sample(1:50,300,replace=TRUE)
x
y <- 3.2*x + rnorm(300,0,40)
y
d_sim <- data.frame(y=y, x=x)
d_sim
mean(d$depth)
summary(d$depth) # Summary stats of one column in d
d[ , 1:2] # Subsetting columns
d[, c("start","end")] # We can also use column names to acheive the same end
d[,1:2]==d[, c("start","end")] # We can also use column names to acheive the same end
d[,1:2]=d[, c("start","end")] # We can also use column names to acheive the same end
d[1,c("start","end")]
d[, "start", drop=FALSE]
d$cent <- d$start >= 25800000 & d$end <= 29700000
d$cent
table(d$cent)
d$diversity <- d$Pi / (10*1000)
plot(cars)
plot(cars)
plot(cars)
plot(cars)
if(condition) {
# Do something
} else {
# Do something else
} else if (condition2) {
d$Pi
d$Pi/(10*1000)
summary(d$total.SNPs)
d$total.SNPs >= 85 # Create logical vector
d[d$total.SNPs >= 85, ] # Subset according to logical vector
d[d$Pi > 16 & d$Percent.GC > 80, ]
d[d$Pi > 16 & d$Percent.GC > 80, c("start","end","depth","Pi")]
d$Percent.GC[d$Pi > 16]
summary(d$depth[d$Percent.GC >= 80])
summary(d$depth[d$Percent.GC < 80])
summary(d$Pi[d$cent])
summary(d$Pi[d$cent])
summary(d$Pi[!d$scent])
d$Pi > 3
which(d$Pi>3)
which(d$Pi>10)[1:4]
d[which.min(d$total.Bases),]
d[which.max(d$depth, ] # Returns row with the maximum element
d[which.max(d$depth),] # Returns row with the maximum element
x <- list(a=1:5,b=rnorm(10))
lapply(x,mean)
x
a <- list(b=1:5,c=rnorm(10))
a
lapply(a,mean)
d <- list(e=1:4,f=rnorm(10),g=rnorm(20,1),h=rnorm(100,5))
lapply(d,mean)
i <- 1:4
lapply(i,runif)
lapply(i,runif)
lapply(i,runif)
lapply(i,runif, min=0,max=10)
j <- list(a=matrix(1:4,2,2),b=matrix(1:6,3,2))
j
lapply(x,function(elt),elt[,1])
lapply(j,function(elt),elt[,1])
lapply(j,function(elt) elt[,1])
lapply(x,mean)
k <- list(l = 1:4, m = rnorm(10), n = rnorm(20,1), o = rnorm(100,5))
lapply(k,mean)
sapply(k,mean)
mean(k)
str(apply)
l <- matrix(rnorm(200), 20, 10)
apply(l, 2, mean)
matrix(rnorm(200), 20, 10)
l <- matrix(rnorm(200), 20, 10) # Create random normal matrix of 200 points
apply(l, 2, print) # Returns vector of length 10 from each column of matrix l
apply(l, 1, print) # Rer
apply(l,1,quantile,probs = c(0.25,0.75))
m <- array(rnorm(2*2*10),c(2,2,10))
m <- array(rnorm(2*2*10),c(2,2,10))
apply(m,c(1,2),mean)
rowMeans(m,dims=2)
array(rnorm(2*2*10),c(2,2,10))
apply(m,c(1,2),mean) # applies mean for each matrices and returns vector of 10
rowMeans(m,dims=2)
m <- array(rnorm(2*2*10),c(2,2,10)) # Returns 10 matrices of 4 normal random variables
apply(m,c(1,2),mean) # applies mean for each matrices and returns 2x2 matrix
rowMeans(m,dims=2) # Does the same thing as the above.
subset(d,Pi > 16 & Percent.GC > 80)
d <- read.csv("Dataset_S1.txt") # Load data
getwd()
setwd("/Users/jdarias/Desktop/grunt-work/bds-files/chapter-08-r/")
d <- read.csv("Dataset_S1.txt") # Load data
subset(d,Pi > 16 & Percent.GC > 80)
head(d, n=3) # Check data
nrow(d) # Check # rows
ncol(d) # Check # columns
dim(d) # Check dimensions (r c)
colnames(d) # Check column names for discrepancies; "X.GC" instead of "%GC"
colnames(d)[12] <- "Percent.GC" # Changed X.GC
subset(d,Pi > 16 & Percent.GC > 80)
subset(d, Pi > 16 & Percent.GC > 80)
subset(d, Pi > 16 & Percent.GC > 80,
c(start,end,Pi,Percent.GC,depth))
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
```
install.packages("ggplot2")
library(ggplot2)
d$position <- d$end + d$start / 2
ggplot(d) + geom_point(aes(x=position, y=diversity))
colnames(d)
ggplot(d) + geom_point(aes(x=position, y=Pi))
ggplot(d,aes(x=position, y=Pi)) + geom point()
ggplot(d,aes(x=position, y=Pi)) + geom_point()
ggplot(d) + geom_point(aes(x=position, y=Pi))
ggplot(d,aes(x=position, y=Pi)) + geom_point()
ggplot(d) + geom_point(aes(x=position, y=diversity, color=cent))
ggplot(d) + geom_point(aes(x=position, y=diversity, color=cent))
ggplot(d) + geom_point(aes(x=position, y=Pi, color=cent))
d$cent <- d$start >= 25800000 & d$end <= 29700000
ggplot(d) + geom_point(aes(x=position, y=Pi, color=cent))
ggplot(d,aes(x=position, y=Pi)) + geom_point()
ggplot(d) + geom_point(aes(x=position, y=Pi, color=cent))
str(mapply)
list(rep(1,4), rep(2,3), rep(3,2), rep(4,1))
mapply(rep, 1:4, 4:1)
noise <- function(n, mean, sd) {
rnorm(n, mean, sd)
}
noise(5, 1, 2)
noise(1:5, 1:5, 2)
noise(5, 1, 2)
mappy(noise,1:5,1:5,2)
mapply(noise,1:5,1:5,2)
list(noise(1,1,2),noise(2,2,2),noise(3,3,2),noise(4,4,2),noise(5,5,2))
str(tapply)
x <- c(rnorm(10), runif(10), rnorm(10,1))
f <- gl(3,10)
f
x
?gl
tapply(x, f, mean)
runif(10)
?runif
tapply(x, f, mean, simplify = FALSE
tapply(x, f, mean)
tapply(x, f, mean)
mean(x[1:10])
mean(x[11:20])
tapply(x,f,mean,simp=FALSE)
tapply(x,f,mean,simplify=FALSE)
tapply(x,f,range)
str(split)
x <- c(rnorm(10), runif(10), rnorm(10,1))
x <- c(rnorm(10), runif(10), rnorm(10,1))
f <- gl(3,10)
split(x,f)
lapply(split(x,f),mean)
library(datasets)
head(airquality)
airquality$Month
s <- split(airquality, airquality$Month)
s
s <- split(airquality, airquality$Month)
s
s
lapply(s, function(x) colMeans(x[, c("Ozone","Solar.R","Wind")]))
sapply(s, function(x) colMeans(x[, c("Ozone","Solar.R", "Wind")]))
sapply(s, function(x) colMeans(x[, c("Ozone","Solar.R", "Wind")], na.rm=TRUE))
x <- rnorm(10)
f1 <- gl(2,5)
f1 <- gl(2,5) # Let's call this factor delimitation "race"
f2 <- gl(5,2) # This one "income"
interaction(f1,f2)
str(split(x,list(f1,f2)))
str(split(x,list(f1,f2),drop=TRUE))
ggplot(d) + geom_point(aes(x=position,y=Pi), alpha=0.01)
ggplot(d) + geom_density(aes(x=Pi), fill="black")
ggplot(d) + geom_density(aes(x=Pi))
ggplot(d) + geom_density(aes(x=Pi), fill="black")
ggplot(d) + geom_density(aes(x=Pi, fill=cent),alpha=0.4)
ggplot(d) + geom_density(aes(x=Pi), fill="black")
ggplot(d, aes(x=depth, y=total.SNPs)) + geom_point() + geom_smooth()
ggplot(d, aes(x=Percent.GC, y=depth)) + geom_point() + geom_smooth()
d$GC.binned <- cut(d$Percent.GC,5)
d$GC.binned
x <- 1:0.1:100
s
x
x <- 1:100:0.1
x <- seq(1,100,0.1)
x
swirl()
library(swirl)
swirl()
rm(list=ls())
swirl()
head(flags)
dim(flags)
exit
swirl()
sapply(flags,unique)
vapply(flags,unique,numeric(1))
ok()
?vapply
sapply(flags,class)
vapply(flags,class,character(1))
?tapply
table(flags$landmass)
table(flags$animate)
tapply(flags$animate,flags$landmass,mean)
tapply(flags$population, flags$red, summary)
tapply(flags$population,flags$landmass,summary)
getwd()
setwd("/Users/jdarias/Desktop/ProgrammingAssignment2/")
makeVector <- function(x = numeric()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
cachemean <- function(x, ...) {
m <- x$getmean()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- mean(data, ...)
x$setmean(m)
m
}
makeVector(c(2,3,4,5,6,7))
x
cachemean(c(2,3,4,5,6,7))
x <- c(1,2,3,4,5,6)
makeVector(x)
cachemean(x)
traceback()
debug(cachemean)
cachemean(x)
cachemean(makeVector(x))
undebug(cachemean)
cachemean(makeVector(x))
mean(x)
d$GC.binned <- cut(d$Percent.GC,5)
d <- read.csv("Dataset_S1.txt") # Load data
getwd()
setwd("~/Desktop/grunt-work/bds-files/chapter-08-r/")
d <- read.csv("Dataset_S1.txt") # Load data
getwd()
ls()
getwd()
d <- read.csv("Dataset_S1.txt") # Load data
read.csv("Dataset_S1.txt")
d <- read.csv("Dataset_S1.txt") # Load data
